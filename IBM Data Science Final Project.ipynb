{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project: Is there a link between the types of restaurants in a city and the obesity rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For all details on the data, methodology, results and observations, refer to the final report here: __https://github.com/faddy-ds/Coursera_Capstone__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import folium\n",
    "\n",
    "import requests\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Retrieve and analyze obesity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe and read data to it\n",
    "\n",
    "obesity_rates_cities = pd.read_csv('Obesity data from CDC - 2011.csv')\n",
    "obesity_rates_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataframe by deleting rows with NaN or missing data & formatting first column to separate City and State\n",
    "\n",
    "obesity_rates_cities.dropna(inplace=True)\n",
    "obesity_rates_cities.drop(columns=['No physical activity'], inplace=True)\n",
    "obesity_rates_cities.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in range(len(obesity_rates_cities['Area'])):\n",
    "    x = obesity_rates_cities['Area'].str.rsplit(\" \", 2)[i][0]\n",
    "    y = x.split(\"-\")[0]\n",
    "    z = x[-2:]\n",
    "    obesity_rates_cities['Area'][i] = y + \", \" + z\n",
    "    obesity_rates_cities['Normal weight'][i] = obesity_rates_cities['Normal weight'].str.split(\"%\")[i][0]\n",
    "    obesity_rates_cities['Overweight'][i] = obesity_rates_cities['Overweight'].str.split(\"%\")[i][0]\n",
    "    obesity_rates_cities['Obese'][i] = obesity_rates_cities['Obese'].str.split(\"%\")[i][0]\n",
    "\n",
    "obesity_rates_cities.set_index('Area', inplace=True)\n",
    "cols = obesity_rates_cities.columns\n",
    "obesity_rates_cities[cols] = obesity_rates_cities[cols].apply(pd.to_numeric, downcast='float', errors='coerce')\n",
    "# obesity_rates_cities.sort_values(by=['Obese'], inplace = True)\n",
    "\n",
    "obesity_rates_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the statistical distribution of data\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "fig_ob, ax_ob = plt.subplots(figsize = (20,10))\n",
    "sns.distplot(obesity_rates_cities['Obese'], color = 'r', kde=False, bins = 191).set_title('Obese')\n",
    "ax_ob.set(xlabel = \"Percentage of city's population in this category\", ylabel = 'Count of cities')\n",
    "plt.setp(ax_ob, xticks = [i for i in range(int(min(obesity_rates_cities['Obese'])), int(max(obesity_rates_cities['Obese'])+2), 1)])\n",
    "\n",
    "fig_ow, ax_ow = plt.subplots(figsize = (20,10))\n",
    "sns.distplot(obesity_rates_cities['Overweight'], color = 'y', kde=False, bins = 191).set_title('Overweight')\n",
    "ax_ow.set(xlabel = \"Percentage of city's population in this category\", ylabel = 'Count of cities')\n",
    "plt.setp(ax_ow, xticks = [i for i in range(int(min(obesity_rates_cities['Overweight'])), int(max(obesity_rates_cities['Overweight'])+2), 1)])\n",
    "\n",
    "fig_n, ax_n = plt.subplots(figsize = (20,10))\n",
    "sns.distplot(obesity_rates_cities['Normal weight'], color = 'g', kde=False, bins = 191).set_title('Normal weight')\n",
    "ax_n.set(xlabel = \"Percentage of city's population in this category\", ylabel = 'Count of cities')\n",
    "plt.setp(ax_n, xticks = [i for i in range(int(min(obesity_rates_cities['Normal weight'])), int(max(obesity_rates_cities['Normal weight'])+2), 1)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the data to identify outliers\n",
    "\n",
    "obesity_rates_cities.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get geographical coordiantes for the cities, using dataset from https://simplemaps.com/data/us-cities\n",
    "\n",
    "city_coord = pd.read_csv('uscities.csv')\n",
    "city_coord.dropna(inplace=True)\n",
    "city_coord.drop(city_coord.columns.difference(['city', 'state_id', 'lat', 'lng']), 1, inplace=True)\n",
    "city_coord['Area'] = city_coord['city'] + ', ' + city_coord['state_id']\n",
    "city_coord.drop(columns = ['city', 'state_id'], inplace=True)\n",
    "city_coord_keep = city_coord.loc[city_coord['Area'].isin(obesity_rates_cities.index)]\n",
    "city_coord_keep.set_index('Area', inplace=True)\n",
    "city_coord_keep.sort_index(inplace = True)\n",
    "city_coord_keep\n",
    "\n",
    "# There are only 160 rows, so 31 of the cities for which I have obesity data are not in the lat-long database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lat-long data into obesity dataframe\n",
    "\n",
    "data = pd.merge(obesity_rates_cities, city_coord_keep, left_index=True, right_index=True)\n",
    "data.rename(columns = {'lat':'Latitude', 'lng':'Longitude'}, inplace = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical analysis of the data\n",
    "\n",
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graphical distribution of data\n",
    "\n",
    "us_map = folium.Map(location=[38, -115], zoom_start=4)\n",
    "\n",
    "for lat, long, obese, area in zip(data['Latitude'], data['Longitude'], data['Obese'], data.index):\n",
    "    label = '{}% of population in {} is obese'.format(obese, area)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, long],\n",
    "        radius = 5,\n",
    "        popup = label,\n",
    "        color = 'blue',\n",
    "        fill = True,\n",
    "        fill_color = '#3186cc',\n",
    "        fill_opacity = 0.7,\n",
    "        parse_html = False).add_to(us_map)\n",
    "\n",
    "us_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Compile most common restaurant categories per city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get 3 most common types of restaurants for each area\n",
    "\n",
    "CLIENT_ID = 'UEHS0BUJQOPZQPPKWNBA1YZSCP3O14SZYGT1ZC0XECDCJFMG'\n",
    "CLIENT_SECRET = '3AM1HHTVARNZV5VMLJKY25YQOXKYHC0M3R45IZL3QQ4LXB5S'\n",
    "VERSION = '20180604'\n",
    "\n",
    "# Below is a test with Akron, OH to test the query and results' format\n",
    "\n",
    "LIMIT = 20\n",
    "category = '4d4b7105d754a06374d81259'\n",
    "intent = 'browse'\n",
    "lat = data.iloc[0, 3]\n",
    "long = data.iloc[0, 4]\n",
    "\n",
    "url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&limit={}&categoryId={}&intent={}'.format(\n",
    "    CLIENT_ID,\n",
    "    CLIENT_SECRET,\n",
    "    VERSION,\n",
    "    lat,\n",
    "    long,\n",
    "    LIMIT,\n",
    "    category, \n",
    "    intent)\n",
    "\n",
    "results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "results[0]['venue']['categories'][0]['name']\n",
    "# requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not specifying a radius defaults to city wide search. The specified category is all \"Food\" venues\n",
    "area_list = data.index\n",
    "latitudes = data['Latitude']\n",
    "longitudes = data['Longitude']\n",
    "category = '4d4b7105d754a06374d81259'\n",
    "intent = 'browse'\n",
    "LIMIT = 100\n",
    "\n",
    "venues = []\n",
    "\n",
    "for areas, lat, long in zip(area_list, latitudes, longitudes):\n",
    "\n",
    "    url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&categoryId={}&intent={}&limit={}'.format(\n",
    "#     url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&categoryId={}&intent={}'.format(\n",
    "        CLIENT_ID, \n",
    "        CLIENT_SECRET, \n",
    "        VERSION, \n",
    "        lat, \n",
    "        long, \n",
    "        category, \n",
    "        intent,\n",
    "        LIMIT)\n",
    "            \n",
    "    results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "    \n",
    "    venues.append([(\n",
    "        areas, \n",
    "        lat, \n",
    "        long, \n",
    "        v['venue']['name'],\n",
    "        v['venue']['categories'][0]['name']) for v in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_venues = pd.DataFrame(columns = ['Area', \n",
    "                  'Area Latitude', \n",
    "                  'Area Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Category'])\n",
    "\n",
    "row = 0\n",
    "for i in range(0, len(venues)):\n",
    "    for j in range(0, len(venues[i])):\n",
    "        food_venues.loc[row] = [venues[i][j][0]] + [venues[i][j][1]] + [venues[i][j][2]] + [venues[i][j][3]] + [venues[i][j][4]]\n",
    "        row = row + 1\n",
    "    \n",
    "display(food_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_venues.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "sns.countplot(x=\"Venue Category\", data=food_venues)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "plt.tight_layout()\n",
    "\n",
    "for p in ax.patches:\n",
    "    x = p.get_x()\n",
    "    y = p.get_y() + p.get_height()\n",
    "    ax.annotate(p.get_height(), (x, y))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most common venue category for each city\n",
    "\n",
    "food_venues_onehot = pd.get_dummies(food_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "food_venues_onehot['Area'] = food_venues['Area']\n",
    "\n",
    "fixed_columns = [food_venues_onehot.columns[-1]] + list(food_venues_onehot.columns[:-1])\n",
    "food_venues_onehot = food_venues_onehot[fixed_columns]\n",
    "\n",
    "venues_grouped = food_venues_onehot.groupby('Area').mean().reset_index() # need to group with totals, not frequencis. ORRR maybe i can use frequencies\n",
    "venues_grouped.set_index('Area', inplace=True)\n",
    "venues_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_venue = pd.DataFrame(columns = ['Most common venue category',\n",
    "                                           'Venue frequency'])\n",
    "\n",
    "for i in range(0, len(venues_grouped.index)):\n",
    "    most_common_venue.loc[i] = [venues_grouped.idxmax(axis=1)[i]] + [venues_grouped.max(axis=1)[i]]\n",
    "\n",
    "most_common_venue.set_index(venues_grouped.index, inplace = True)\n",
    "\n",
    "most_common_venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing all data into 1 dataset\n",
    "\n",
    "total_data = pd.merge(data, most_common_venue, left_index=True, right_index=True)\n",
    "total_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Attempt to find relationship between restaurant type & obesity rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "\n",
    "total_data['Venue frequency'] = total_data['Venue frequency']*100\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = total_data[0:120]\n",
    "test_data = total_data[121:160]\n",
    "\n",
    "# x = train_data[['Obese', 'Venue frequency']]\n",
    "# y = train_data['Most common venue category']\n",
    "# x_test = test_data[['Obese', 'Venue frequency']]\n",
    "# y_test = test_data['Most common venue category']\n",
    "\n",
    "x = train_data[['Obese', 'Venue frequency', 'Latitude', 'Longitude']]\n",
    "y = train_data['Most common venue category']\n",
    "x_test = test_data[['Obese', 'Venue frequency', 'Latitude', 'Longitude']]\n",
    "y_test = test_data['Most common venue category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KN algorithm\n",
    "\n",
    "# find optimal k\n",
    "scores = pd.DataFrame(columns=['K', 'Score'])\n",
    "for i in range(1, 120):\n",
    "    kn = KNeighborsClassifier(n_neighbors=i)\n",
    "    kn.fit(x, y)\n",
    "    scores.loc[i] = [i] + [kn.score(x_test, y_test)]\n",
    "\n",
    "sns.lineplot(x=\"K\", y=\"Score\", data=scores)\n",
    "\n",
    "scores2 = pd.DataFrame(columns=['K', 'Score'])\n",
    "for i in range(1, 120):\n",
    "    kn = KNeighborsClassifier(n_neighbors=i, weights='distance')\n",
    "    kn.fit(x, y)\n",
    "    scores2.loc[i] = [i] + [kn.score(x_test, y_test)]\n",
    "\n",
    "sns.lineplot(x=\"K\", y=\"Score\", data=scores2)\n",
    "\n",
    "display(scores.loc[scores['Score'].idxmax()], scores2.loc[scores2['Score'].idxmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on 2/3 of the data, and test on 1/3\n",
    "\n",
    "kn = KNeighborsClassifier(n_neighbors=18)\n",
    "kn.fit(x, y)\n",
    "kn.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Naive Bayes classifiers\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(x, y)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree classifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(x, y)\n",
    "dt.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the KNN algorithm\n",
    "\n",
    "y_pred = kn.predict(x_test)\n",
    "y_true = y_test\n",
    "\n",
    "# Jaccard index\n",
    "display(jaccard_score(y_true, y_pred, average = None))\n",
    "\n",
    "# F1 score\n",
    "f1_score(y_true, y_pred, average = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
